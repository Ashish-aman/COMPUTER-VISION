# -*- coding: utf-8 -*-
"""M22MA002_PA3Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zzg6t5al0TukAkvLoRk3Flklq7Ias9cH
"""

import urllib.request
import tarfile
import pickle
import numpy as np
import cv2 as cv
from google.colab.patches import cv2_imshow
from sklearn.cluster import KMeans
# Define the CIFAR-10 dataset download URL
url = 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'

# Download CIFAR-10 dataset
filename, headers = urllib.request.urlretrieve(url)

# Extract CIFAR-10 dataset from tar.gz file
with tarfile.open(filename, 'r:gz') as tar:
    tar.extractall()

# Load CIFAR-10 data
def unpickle(file):
    with open(file, 'rb') as fo:
        data = pickle.load(fo, encoding='bytes')
    return data

# Load training data
train_data = None
train_labels = None
for i in range(1, 6):
    batch_file = f'cifar-10-batches-py/data_batch_{i}'
    batch = unpickle(batch_file)
    if i == 1:
        train_data = batch[b'data']
        train_labels = batch[b'labels']
    else:
        train_data = np.concatenate((train_data, batch[b'data']), axis=0)
        train_labels += batch[b'labels']

# Load test data
test_batch_file = 'cifar-10-batches-py/test_batch'
test_batch = unpickle(test_batch_file)
test_data = test_batch[b'data']
test_labels = test_batch[b'labels']
train_data=train_data[0:20000]
test_data = test_data[0:1000]

test_data[0:30]

from sklearn.svm import SVC

scale_ift = cv.SIFT_create()
# Convert labels to numpy arrays
train_labels = np.array(train_labels[:2000])
test_labels = np.array(test_labels[0:1000])

# Reshape data to image shape (32, 32, 3)
train_data_transposed = train_data[0:2000].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)
test_data_transposed = test_data[0:100].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)

bow_list = []
len(train_data),train_labels.shape,test_data.shape,test_labels.shape

#Function to get key descriptors via SIFT
def create_bins(keypoints,kmeans,clusters):
    bag_of_words = []
    for des in keypoints:
        histogram = np.zeros(clusters)
        for i in range(len(des)):
            index = kmeans.predict([des[i]])
            histogram[index] += 1
        bag_of_words.append(histogram)
    return bag_of_words
def get_keypoints(image_dataset):
    keypoints = []
    for sample in image_dataset:
        # img = img.reshape(3, 32, 32).transpose(1, 2, 0)
        bnw_image = cv.cvtColor(sample, cv.COLOR_BGR2GRAY)
        kp, des = scale_ift.detectAndCompute(bnw_image, None)
        keypoints.append(des)
    keypoints = [kp if kp is not None else np.zeros((1, 128)) for kp in keypoints]
    kps = np.concatenate(keypoints, axis=0)
    return keypoints,kps

keypoints, kps = get_keypoints(train_data_transposed)

len(keypoints),kps.shape

km_model = KMeans(n_clusters=100)
km_model.fit(kps)

test_labels[0:30]

for des in keypoints:
    words_in_image = np.zeros(100)
    for i in range(len(des)):
        index = km_model.predict([des[i]])
        words_in_image[index] =words_in_image[index]+ 1
    bow_list.append(words_in_image)

labels = np.array(train_labels)
print(f"shape of labels: {labels.shape}")
bow_points = np.array(bow_list)
print(f"shape of bow_points: {bow_points.shape}")
# clf = SVC(kernel='linear', C=1.0)
linear_cl = SVC(kernel='linear', C=1.0)
linear_cl.fit(bow_points, labels)

import numpy as np
y = test_labels
predictions = []
for i in range(len(test_data)):
    data = test_data[i].reshape(3, 32, 32).transpose(1, 2, 0)
    ns, points = scale_ift.detectAndCompute(data, None)
    points = np.pad(points, ((0, 0), (0, 128 - des.shape[1])), 'constant', constant_values=0)
    index = km_model.predict(points.astype(np.float64))
    hist = np.histogram(index, bins=100)[0]
    label = linear_cl.predict([hist])[0]
    predictions.append(label)

predictions[0:20]

# calculate the accuracy, precision, recall and f1-score, AP and mAP
accuracy = np.sum(np.array(predictions) == np.array(y)) / len(y)
precision = np.sum(np.array(predictions) == np.array(y)) / np.sum(np.array(predictions) == 1)
recall = np.sum(np.array(predictions) == np.array(y)) / np.sum(np.array(y) == 1)
f1_score = 2 * (precision * recall) / (precision + recall)
AP = np.sum(np.array(predictions) == np.array(y)) / len(y)

print(f"accuracy: {accuracy}")
print(f"precision: {precision}")
print(f"recall: {recall}")
print(f"f1_score: {f1_score}")
print(f"AP: {AP}")

import numpy as np
import matplotlib.pyplot as plt

def plot_graph(recall, precision):
    plt.figure(figsize=(10, 8))
    plt.title('Precision-Recall Curve')
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.plot(recall, precision, marker='.', label='Precision-Recall Curve')
    plt.legend()
    plt.show()

t_p=0
f_p = 0
od = np.argsort(predictions)[::-1]
test_labels = np.asarray(test_labels)[od]
th = np.zeros_like(test_labels, dtype=float)
ppredictions = np.asarray(predictions)
ppredictions=ppredictions[od]
recall = np.zeros_like(test_labels, dtype=float)
f_n = np.sum(test_labels)
precision = np.zeros_like(test_labels, dtype=float)
for i in range(len(ppredictions)):
    if test_labels[i]:
        t_p += 1
        f_n -= 1
    else:
        f_p += 1
    th[i] = ppredictions[i]
    temp1 = (t_p + f_p)
    temp2 = (t_p + f_n)
    precision[i] = t_p / temp1
    recall[i] = t_p / temp2

plot_graph(recall, precision)

"""## Testing the model"""

def query_image(kmeans,linear_cl):
  ind = np.random.randint(0, len(batch[b'data']))
  scale_ift=cv.SIFT_create()
  query = np.random.randint(0, len(test_data))
  query_image = test_data_transposed[query]
  query_label = test_labels[query]
  print(f"Query Image Class is {query_label}")
  _, descriptors = scale_ift.detectAndCompute(query_image.reshape(3, 32, 32).transpose(1, 2, 0), None)
  near_images_index = km_model.predict(np.array(des,dtype=np.float64))
  query_histogram, _ = np.histogram(near_images_index, bins=100, range=(0, 100))
  y_query = linear_cl.predict([query_histogram])
  near_images_index = np.where(train_labels == y_query[0])
  near_images_index= near_images_index[0]
  near_images=near_images_index[0:5]
  return near_images, query

import matplotlib.pyplot as plt


def show_near_images(near_images,train_data_transposed,query_idx):
  # Set up the figure with subplots
  fig, axes = plt.subplots(2, 3, figsize=(10, 6))
  axes = axes.flatten()
  axes[0].imshow(test_data[query_idx].reshape(3, 32, 32).transpose(1, 2, 0))
  axes[0].set_title("Query Image")
  axes[0].axis('off')
  for i in range(5):
    axes[i+1].imshow(train_data[near_images[i]].reshape(3, 32, 32).transpose(1, 2, 0))
    axes[i+1].set_title(f"Near Image {i+1}")
    axes[i+1].axis('off')
  plt.tight_layout()
  plt.show()
near_images,query_image=query_image(km_model,linear_cl)
show_near_images(near_images,train_data_transposed,query_image)

